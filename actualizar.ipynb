{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ecee563e-6ae0-46f8-84f3-30730ddcaeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facebook_scraper import get_posts\n",
    "import json\n",
    "import pandas as pd\n",
    "import twitter\n",
    "import internetarchive as ia\n",
    "import requests\n",
    "import os\n",
    "import datetime as dt\n",
    "from git import Repo\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce5e35c9-4c6f-46c8-9c35-1d53bde03ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSYiPWLCf9_HWB51cIryodmVlDg4RQS_AeccuJjkz9xVtDx7Y5tfk9RaF94BrVdO5vakBo5dUktZawh/pub?gid=0&single=true&output=csv\"\n",
    "metadatos_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vSYiPWLCf9_HWB51cIryodmVlDg4RQS_AeccuJjkz9xVtDx7Y5tfk9RaF94BrVdO5vakBo5dUktZawh/pub?gid=1875795980&single=true&output=csv\"\n",
    "directory = 'reportes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "927bd168-7a78-42d9-9636-9c7f2eaa5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_credenciales():\n",
    "    with open('credenciales.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def auth_twitter():\n",
    "    \"Autenticar en Twitter para realizar consultas al API\"\n",
    "\n",
    "    return twitter.Api(consumer_key = credenciales['twitter']['consumer_key'],\n",
    "                       consumer_secret = credenciales['twitter']['consumer_secret'],\n",
    "                       access_token_key = credenciales['twitter']['access_token_key'],\n",
    "                       access_token_secret = credenciales['twitter']['access_token_secret'],\n",
    "                       tweet_mode='extended')\n",
    "\n",
    "def read_metadata():\n",
    "    \"Descarga los metadatos de google sheets, filtra sólo aquellos con una fuente y crea una columna de status_id\"\n",
    "\n",
    "    meta = pd.read_csv(metadatos_url, parse_dates=['fecha'], index_col=['fecha'])\n",
    "    meta = meta.dropna(subset=['La Paz', 'Cochabamba', 'Oruro'])\n",
    "    return meta\n",
    "\n",
    "def filtrar_nuevos(meta):\n",
    "    \"Devuelve sólo las entradas que no hayan sido descargadas previamente.\"\n",
    "\n",
    "    viejos = [dt.datetime.strptime(filename.split('.')[0].split('_')[-1], '%Y%m%d') for filename in os.listdir(directory)]\n",
    "    return meta[~meta.index.isin(viejos)]\n",
    "\n",
    "def create_identifier(dep, fecha):\n",
    "    return 'reportesdepartamentalescovid19bolivia_{}_{}'.format(dep.lower().replace(' ', '_'), fecha.strftime('%Y%m%d'))\n",
    "\n",
    "def save_image(url, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(requests.get(url).content)\n",
    "\n",
    "def parse_facebook(url, dep, fecha):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        post = [post for post in get_posts(post_urls=[url], cookies='cookies.json')][0]\n",
    "    post_meta = {\n",
    "        \"source\": post['post_url'],\n",
    "        \"creator\": post['username'],\n",
    "        \"description\": post['text'],\n",
    "    }\n",
    "    identifier = create_identifier(dep, fecha)\n",
    "    filename = '{}/{}.jpeg'.format(directory, identifier)\n",
    "    save_image(post['images'][0], filename)\n",
    "    return post_meta, identifier, filename\n",
    "\n",
    "def parse_twitter(url, dep, fecha):\n",
    "    tweet_id = url.split('/')[-1]\n",
    "    statuses = tw.GetStatuses([tweet_id])\n",
    "    status = statuses[0]._json\n",
    "    post_meta = {\n",
    "        \"source\": url,\n",
    "        \"creator\": status['user']['name'],\n",
    "        \"description\": status['full_text']\n",
    "    }\n",
    "    identifier = create_identifier(dep, fecha)\n",
    "    media = status['entities']['media'][0]['media_url']\n",
    "    filename = '{}/{}.{}'.format(directory, identifier, media.split('.')[-1])\n",
    "    save_image(media, filename)\n",
    "    return post_meta, identifier, filename\n",
    "\n",
    "def upload_archive(dep, fecha, post_meta, identifier, filename):\n",
    "\n",
    "    ia_meta = {'title': 'Reporte de Covid-19 en {}, Bolivia para el {}'.format(dep, fecha.strftime('%-d de %B, %Y')),\n",
    "               'description': post_meta['description'],\n",
    "               'source': post_meta['source'],\n",
    "               'creator': post_meta['creator'],\n",
    "               'mediatype': 'image',\n",
    "               'date': fecha.strftime('%Y-%m-%d')}\n",
    "\n",
    "    ia.upload(identifier,\n",
    "              filename,\n",
    "              metadata=ia_meta,\n",
    "              access_key = credenciales[\"ia\"][\"access\"],\n",
    "              secret_key = credenciales[\"ia\"][\"secret\"])\n",
    "    print('https://archive.org/details/{} : {}'.format(identifier, post_meta['source']))\n",
    "\n",
    "def archivar(meta):\n",
    "    for fecha, row in meta.iterrows():\n",
    "        valores = row.to_dict()\n",
    "        for dep in valores.keys():\n",
    "            if type(valores[dep]) == str:\n",
    "                url = valores[dep]\n",
    "                if 'facebook.com' in url:\n",
    "                    post_meta, identifier, filename = parse_facebook(url, dep, fecha)\n",
    "                if 'twitter.com' in url:\n",
    "                    post_meta, identifier, filename = parse_twitter(url, dep, fecha)\n",
    "                upload_archive(dep, fecha, post_meta, identifier, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7339b0e5-d110-4f11-b1d5-2c8d5872142e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_la_paz_20220121 : https://facebook.com/story.php?story_fbid=4969355603085432&id=1140266705994360\n",
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_cochabamba_20220121 : https://facebook.com/story.php?story_fbid=4767553753339322&id=957131637714905\n",
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_oruro_20220121 : https://facebook.com/story.php?story_fbid=300792545409743&id=100064370004661\n",
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_potosi_20220121 : https://facebook.com/story.php?story_fbid=478642363722300&id=110681273851746\n",
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_tarija_20220121 : https://facebook.com/story.php?story_fbid=994978644464146&id=396941987601151\n",
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_chuquisaca_20220121 : https://facebook.com/story.php?story_fbid=768352557901499&id=108534767216618\n",
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_beni_20220121 : https://facebook.com/story.php?story_fbid=1882778561929917&id=517750071766113\n",
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_pando_20220121 : https://facebook.com/story.php?story_fbid=1659443837736378&id=132468257100618\n",
      "https://archive.org/details/reportesdepartamentalescovid19bolivia_bolivia_20220121 : https://twitter.com/abi_bolivia/status/1484726696515444741\n"
     ]
    }
   ],
   "source": [
    "credenciales = load_credenciales()\n",
    "tw = auth_twitter()\n",
    "meta = filtrar_nuevos(read_metadata())\n",
    "archivar(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "019b534b-0fc0-4eee-b6c2-49114b0622f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidar():\n",
    "    \"\"\"\n",
    "    Sincroniza sheets\n",
    "    \"\"\"\n",
    "    \n",
    "    def download_sheet(url, filename):\n",
    "        datos = requests.get(url).text\n",
    "        datos = datos.replace('\\r','')\n",
    "        with open(filename, 'w+') as f:\n",
    "            f.write(datos)\n",
    "            \n",
    "    for url, filename in zip([metadatos_url, datos_url], ['metadata.csv', 'descartados.csv']):\n",
    "        download_sheet(url, filename)\n",
    "\n",
    "def format_descartados():\n",
    "    \n",
    "    start = '2022-01-21'\n",
    "    descartados = pd.read_csv('descartados.csv', parse_dates=['Fecha'], index_col=['Fecha'])\n",
    "\n",
    "    for fecha, row in descartados.loc[start:].iterrows():\n",
    "        if row[dep_cols].isna().sum() == 1:\n",
    "            missing = row[\"Bolivia\"] - row[dep_cols].sum()\n",
    "            row.loc[row[row.isna()].index] = missing\n",
    "    \n",
    "    return descartados\n",
    "\n",
    "def format_pruebas():\n",
    "    pruebas = (casos[dep_cols] + descartados[dep_cols]).dropna()\n",
    "    empty = pd.DataFrame(index=pd.date_range(pruebas.index.min(), pruebas.index.max()), columns=dep_cols)\n",
    "    pruebas = pd.concat([pruebas, empty])\n",
    "    pruebas = pruebas[~pruebas.index.duplicated()].sort_index()\n",
    "    pruebas = pruebas.interpolate().diff().dropna().astype(int)\n",
    "    return pruebas\n",
    "\n",
    "def format_results():\n",
    "    dep_cols = ['La Paz', 'Cochabamba', 'Santa Cruz', 'Oruro', 'Potosi', 'Tarija', 'Chuquisaca', 'Beni', 'Pando']\n",
    "    descartados = format_descartados()\n",
    "    casos = pd.read_csv('https://raw.githubusercontent.com/mauforonda/covid19-bolivia-udape/master/confirmados_acumulados.csv', parse_dates=[0], index_col=0)\n",
    "    casos = casos.rename(columns={'Potosí':'Potosi'})\n",
    "    pruebas = format_pruebas()\n",
    "    positividad = (casos.diff().dropna() / pruebas).dropna()\n",
    "    return descartados, pruebas, positividad\n",
    "\n",
    "def save_results(descartados, pruebas, positividad):\n",
    "    descartados.to_csv('descartados.csv', float_format=\"%.0f\")\n",
    "    pruebas.to_csv('pruebas.csv', float_format=\"%.0f\")\n",
    "    positividad.to_csv('positividad.csv', float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a4a89bbc-a21e-4d98-b820-f28666f83156",
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidar()\n",
    "descartados, pruebas, positividad = format_results()\n",
    "save_results(descartados, pruebas, positividad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4da4fcc2-b5a9-4a6f-a61b-d9ff5adc2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    \"\"\"\n",
    "    Actualiza el repositorio\n",
    "    \"\"\"\n",
    "    \n",
    "    last_update = pd.read_csv('metadata.csv', parse_dates=['fecha']).fecha.max()\n",
    "    repository = Repo('.')\n",
    "    repository.index.add('*')\n",
    "    repository.index.commit(last_update.strftime('%Y-%m-%d'))\n",
    "    repository.remotes.origin.push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d83587-5f47-4131-afd1-e771fbbbce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "update()"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
